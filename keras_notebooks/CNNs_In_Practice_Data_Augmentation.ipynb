{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the effect of using data augmentation for training CNNs. In particular, we will load a subset of the CIFAR10 dataset will both train a CNN with and without data augmentation. In the following, we will make use of keras, which simplies training CNNs a lot. Note that we will make use of tensorflow as backend. This permits, for instance, to use tensorboard to visualize the model and the output generated.\n",
    "\n",
    "This tutorial is based on a couple of other tutorials that are available online. It might be worse checking them out as well at some point!\n",
    "* [http://parneetk.github.io/blog/cnn-cifar10/](http://parneetk.github.io/blog/cnn-cifar10/)\n",
    "* [https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "* [https://github.com/stratospark/food-101-keras](https://github.com/stratospark/food-101-keras)\n",
    "* [https://chsasank.github.io/keras-tutorial.html](https://chsasank.github.io/keras-tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Cropping2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which depicts a labeled set of images beloning to 10 classes. For this tutorial, we will also reduce the size of the training set to (a) speed up training and to (b) mimic lack of labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "\n",
    "# only consider a small subset of the training data\n",
    "n_instances_train = 1000\n",
    "n_instances_test = 2000\n",
    "train_features = train_features[:n_instances_train, :, :, :]\n",
    "train_labels = train_labels[:n_instances_train]\n",
    "test_features = test_features[:n_instances_test, :, :, :]\n",
    "test_labels = test_labels[:n_instances_test]\n",
    "num_classes = len(numpy.unique(train_labels))\n",
    "\n",
    "print(\"Number of training instances: %i\" % train_features.shape[0])\n",
    "print(\"Number of testing instances: %i\" % test_features.shape[0])\n",
    "print(\"Number of classes: %i\" % num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's plot one image instance per class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "all_class_names = ['airplane','automobile','bird','cat','deer', 'dog','frog','horse','ship','truck']\n",
    "\n",
    "for i in range(num_classes):\n",
    "    \n",
    "    # get first image of class i \n",
    "    idx = numpy.where(train_labels[:]==i)[0]\n",
    "    all_images_class_i = train_features[idx]\n",
    "    im = numpy.transpose(all_images_class_i[0,::], (1, 2, 0))\n",
    "    \n",
    "    # plot image\n",
    "    ax = fig.add_subplot(1, 10, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(all_class_names[i])\n",
    "    plt.imshow(im)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training CNNs via keras, it might make sense to rescale the pixel values to [0,1] (such that the default values depict good model parameter assignments). In addition, we need to convert each label to a binary class vector. For instance, an instance with label 1 is mapped to a vector (0,1,0,0,0,0,0,0,0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale pixel values from [0,255] to [0,1]\n",
    "train_features = train_features.astype('float32') / 255\n",
    "test_features = test_features.astype('float32') / 255\n",
    "\n",
    "# convert each class label to a binary vector\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a convolutional neural network with keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(3, 32, 32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "original_weights_save = model.get_weights()\n",
    "\n",
    "print(\"Training model ...\")\n",
    "model_info = model.fit(train_features, \n",
    "                       train_labels, \n",
    "                       batch_size=128, \n",
    "                       nb_epoch=150, \n",
    "                       validation_data = (test_features, test_labels), \n",
    "                       verbose=1)\n",
    "trained_weights_save = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(numpy.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    axs[0].set_ylim([0,1.0])\n",
    "\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(numpy.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    axs[1].set_ylim([0,1.1*max(numpy.array(model_history.history['loss']).max(), numpy.array(model_history.history['val_loss']).max())])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    \n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = numpy.argmax(result, axis=1)\n",
    "    true_class = numpy.argmax(test_y, axis=1)\n",
    "    num_correct = numpy.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    \n",
    "    return (accuracy * 100)\n",
    "\n",
    "\n",
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "\n",
    "# compute test accuracy\n",
    "print(\"Accuracy on test data is: %0.2f\" % accuracy(test_features, test_labels, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network defined above achieves an accuracy of about 45-46 percent. A common way to improve the performance of such networks is to augment the data by artificially creating \"new\" training examples via rotating, shifting, mirroring, ... the given training instances. Keras provides the ImageDataGenerator class, which simplifies this process a lot! Have a look at the [documentation](https://keras.io/preprocessing/image/) and modifify the code below to improve the test accuracy!\n",
    "\n",
    "Note: You should be able to rerun only this last cell. Further, 100 epochs should be enough to get a slightly better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest',\n",
    "        )\n",
    "\n",
    "# option 1: continue training; less epochs are enough\n",
    "model.set_weights(trained_weights_save)\n",
    "nb_epoch = 100\n",
    "\n",
    "# option 2: retrain from scratch; here, more epochs are needed!\n",
    "# model.set_weights(original_weights_save)\n",
    "# nb_epoch = 400\n",
    "\n",
    "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
    "                                 samples_per_epoch = train_features.shape[0], \n",
    "                                 nb_epoch = nb_epoch, \n",
    "                                 validation_data = (test_features, test_labels), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "\n",
    "# compute test accuracy\n",
    "print(\"Accuracy on test data is: %0.2f\" % accuracy(test_features, test_labels, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
