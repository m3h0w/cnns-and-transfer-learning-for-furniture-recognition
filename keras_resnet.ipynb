{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "import gc\n",
    "import h5py\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "FEATURES_LOCATION = './features_resnet/'\n",
    "F_CORE = 'cnn_features_'\n",
    "\n",
    "def get_label_from_path(file):\n",
    "    return file.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "def load_data(mode):\n",
    "    if(mode == 'test'):\n",
    "        pickle_path = F_CORE + mode\n",
    "        data = pickle.load(open(FEATURES_LOCATION + pickle_path + '.pkl', 'rb'))\n",
    "        to_return = {}\n",
    "        for key, value in list(data.items()):\n",
    "            to_return[get_label_from_path(key)] = value.reshape(-1,)\n",
    "        return to_return, None\n",
    "    \n",
    "    pickle_path = F_CORE + mode + '_'\n",
    "    \n",
    "    data = {}\n",
    "    for i in range(1,129):\n",
    "        data[i] = pickle.load(open(FEATURES_LOCATION + pickle_path + str(i) + '.pkl', 'rb'))\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    for key, value in list(data.items()):\n",
    "        the_class = key\n",
    "        features = np.array(list(value.values()))\n",
    "        for feature in features:\n",
    "            y.append(the_class)\n",
    "            X.append(feature)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = load_data('train')\n",
    "X_val, y_val = load_data('valid')\n",
    "\n",
    "# Extract number of labels in the training data\n",
    "num_labels = np.unique(y).shape[0]\n",
    "num_features = X.shape[1]\n",
    "num_trainobs = X.shape[0]\n",
    "\n",
    "# Balance labels\n",
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "# Create one hot encoding for training and validation features\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y)\n",
    "y = lb.transform(y)\n",
    "y_val = lb.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, _ = load_data('test')\n",
    "X_test_arr = np.array(list(X_test.values()))\n",
    "X_test_arr = X_test_arr[:, np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 192171 samples, validate on 6309 samples\n",
      "Epoch 1/30\n",
      "192171/192171 [==============================] - 16s 83us/step - loss: 1.3942 - acc: 0.6318 - val_loss: 1.0440 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69742, saving model to checkpoint.h5\n",
      "Epoch 2/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.8912 - acc: 0.7394 - val_loss: 0.9344 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69742 to 0.72611, saving model to checkpoint.h5\n",
      "Epoch 3/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.7798 - acc: 0.7690 - val_loss: 0.8838 - val_acc: 0.7396\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72611 to 0.73958, saving model to checkpoint.h5\n",
      "Epoch 4/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.7154 - acc: 0.7853 - val_loss: 0.8523 - val_acc: 0.7483\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73958 to 0.74830, saving model to checkpoint.h5\n",
      "Epoch 5/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.6655 - acc: 0.7998 - val_loss: 0.8195 - val_acc: 0.7592\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74830 to 0.75923, saving model to checkpoint.h5\n",
      "Epoch 6/30\n",
      "192171/192171 [==============================] - 9s 47us/step - loss: 0.6270 - acc: 0.8101 - val_loss: 0.8067 - val_acc: 0.7657\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.75923 to 0.76573, saving model to checkpoint.h5\n",
      "Epoch 7/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.5933 - acc: 0.8184 - val_loss: 0.7944 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.76573 to 0.76763, saving model to checkpoint.h5\n",
      "Epoch 8/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.5676 - acc: 0.8259 - val_loss: 0.7894 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.76763 to 0.76843, saving model to checkpoint.h5\n",
      "Epoch 9/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.5422 - acc: 0.8323 - val_loss: 0.7825 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.76843 to 0.77255, saving model to checkpoint.h5\n",
      "Epoch 10/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.5215 - acc: 0.8389 - val_loss: 0.7843 - val_acc: 0.7706\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.5002 - acc: 0.8445 - val_loss: 0.7631 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.77255 to 0.77952, saving model to checkpoint.h5\n",
      "Epoch 12/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.4821 - acc: 0.8497 - val_loss: 0.7682 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.77952 to 0.77984, saving model to checkpoint.h5\n",
      "Epoch 13/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.4663 - acc: 0.8534 - val_loss: 0.7706 - val_acc: 0.7771\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.4515 - acc: 0.8583 - val_loss: 0.7600 - val_acc: 0.7811\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.77984 to 0.78111, saving model to checkpoint.h5\n",
      "Epoch 15/30\n",
      "192171/192171 [==============================] - 9s 47us/step - loss: 0.4345 - acc: 0.8629 - val_loss: 0.7620 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.78111 to 0.78301, saving model to checkpoint.h5\n",
      "Epoch 16/30\n",
      "192171/192171 [==============================] - 8s 44us/step - loss: 0.4226 - acc: 0.8665 - val_loss: 0.7627 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.78301 to 0.78301, saving model to checkpoint.h5\n",
      "Epoch 17/30\n",
      "192171/192171 [==============================] - 8s 44us/step - loss: 0.4073 - acc: 0.8709 - val_loss: 0.7706 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.78301 to 0.78396, saving model to checkpoint.h5\n",
      "Epoch 18/30\n",
      "192171/192171 [==============================] - 8s 44us/step - loss: 0.3957 - acc: 0.8741 - val_loss: 0.7602 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.78396 to 0.78697, saving model to checkpoint.h5\n",
      "Epoch 19/30\n",
      "192171/192171 [==============================] - 9s 44us/step - loss: 0.3849 - acc: 0.8774 - val_loss: 0.7722 - val_acc: 0.7851\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.3721 - acc: 0.8808 - val_loss: 0.7709 - val_acc: 0.7838\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.3598 - acc: 0.8852 - val_loss: 0.7926 - val_acc: 0.7832\n",
      "\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.3517 - acc: 0.8871 - val_loss: 0.7701 - val_acc: 0.7873\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.78697 to 0.78729, saving model to checkpoint.h5\n",
      "Epoch 23/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.3428 - acc: 0.8897 - val_loss: 0.7802 - val_acc: 0.7846\n",
      "\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.3343 - acc: 0.8921 - val_loss: 0.7767 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.78729 to 0.78967, saving model to checkpoint.h5\n",
      "Epoch 25/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.3249 - acc: 0.8949 - val_loss: 0.7852 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/30\n",
      "192171/192171 [==============================] - 9s 48us/step - loss: 0.3156 - acc: 0.8979 - val_loss: 0.7826 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.3095 - acc: 0.8997 - val_loss: 0.7922 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/30\n",
      "192171/192171 [==============================] - 9s 45us/step - loss: 0.3025 - acc: 0.9008 - val_loss: 0.7926 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.2954 - acc: 0.9041 - val_loss: 0.8020 - val_acc: 0.7838\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/30\n",
      "192171/192171 [==============================] - 9s 46us/step - loss: 0.2870 - acc: 0.9066 - val_loss: 0.7990 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1537376ca90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustration that the code runs (The 79.41% val acc was achieved with more epochs)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,1,2048)))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(units=1024, activation='tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=128, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.00025, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "callbacks= [keras.callbacks.ModelCheckpoint('checkpoint.h5', monitor='val_acc', verbose=2, save_best_only=True, mode='auto', period=1)]\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=30, batch_size=512, validation_data=(X_val, y_val), callbacks=callbacks, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6309/6309 [==============================] - 1s 95us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7973589453309476, 0.7941036614407675]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "model_test = keras.models.load_model('ResNetTop_ValAcc7941.h5')\n",
    "model_test.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "y_pred_oh = model_test.predict(X_test_arr)\n",
    "# Convert predictions from one-hot to actual labels and print csv\n",
    "y_pred = lb.inverse_transform(y_pred_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for i, index in enumerate(X_test.keys()):\n",
    "    predictions[int(index)] = y_pred[i]\n",
    "    \n",
    "from collections import Counter\n",
    "counted = Counter(predictions.values())\n",
    "most_common_class = counted.most_common()[0][0]\n",
    "\n",
    "for index in range(1, 12801):\n",
    "    if(index not in predictions.keys()):\n",
    "        predictions[index] = most_common_class\n",
    "        \n",
    "ids = []\n",
    "values = []\n",
    "for key, value in predictions.items():\n",
    "    ids.append(key)\n",
    "    values.append(value)\n",
    "    \n",
    "out_dict = {}\n",
    "out_dict['id'] = ids\n",
    "out_dict['predicted'] = values\n",
    "\n",
    "keys = sorted(out_dict.keys())\n",
    "COL_WIDTH = 6\n",
    "FMT = \"%%-%ds\" % COL_WIDTH\n",
    "\n",
    "with open('predictions.csv', 'w') as csv:\n",
    "    # Write keys    \n",
    "    csv.write(','.join([k for k in keys]) + '\\n')\n",
    "\n",
    "    # Assume all values of dict are equal\n",
    "    for i in range(len(out_dict[keys[0]])):\n",
    "        csv.write(','.join([FMT % out_dict[k][i] for k in keys]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Setting layer <keras.engine.topology.InputLayer object at 0x00000154D1192DD8> to non-trainable\n",
      "1: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1A5D2E8> to non-trainable\n",
      "2: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D151BE10> to non-trainable\n",
      "3: Setting layer <keras.layers.core.Activation object at 0x00000154D15B7F60> to non-trainable\n",
      "4: Setting layer <keras.layers.pooling.MaxPooling2D object at 0x00000154D1669978> to non-trainable\n",
      "5: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1BB1B00> to non-trainable\n",
      "6: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CB8BF4E0> to non-trainable\n",
      "7: Setting layer <keras.layers.core.Activation object at 0x00000154D1C07C88> to non-trainable\n",
      "8: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CB8E5C18> to non-trainable\n",
      "9: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CB8D89E8> to non-trainable\n",
      "10: Setting layer <keras.layers.core.Activation object at 0x00000154CB92D898> to non-trainable\n",
      "11: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CB9C2518> to non-trainable\n",
      "12: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CBA0C6D8> to non-trainable\n",
      "13: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CB9B22B0> to non-trainable\n",
      "14: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBA85D30> to non-trainable\n",
      "15: Setting layer <keras.layers.merge.Add object at 0x00000154CBADDF98> to non-trainable\n",
      "16: Setting layer <keras.layers.core.Activation object at 0x00000154CBB51B70> to non-trainable\n",
      "17: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CBB51898> to non-trainable\n",
      "18: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBBB3048> to non-trainable\n",
      "19: Setting layer <keras.layers.core.Activation object at 0x00000154CBC0C5C0> to non-trainable\n",
      "20: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CBC44C88> to non-trainable\n",
      "21: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBC3DE10> to non-trainable\n",
      "22: Setting layer <keras.layers.core.Activation object at 0x00000154CBCA0198> to non-trainable\n",
      "23: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CBD24978> to non-trainable\n",
      "24: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBD188D0> to non-trainable\n",
      "25: Setting layer <keras.layers.merge.Add object at 0x00000154CBD6BB70> to non-trainable\n",
      "26: Setting layer <keras.layers.core.Activation object at 0x00000154CBDF6208> to non-trainable\n",
      "27: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CBDF6080> to non-trainable\n",
      "28: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBE38B70> to non-trainable\n",
      "29: Setting layer <keras.layers.core.Activation object at 0x00000154CBE86C18> to non-trainable\n",
      "30: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CBED9E48> to non-trainable\n",
      "31: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBECFBE0> to non-trainable\n",
      "32: Setting layer <keras.layers.core.Activation object at 0x00000154CBF85358> to non-trainable\n",
      "33: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC007780> to non-trainable\n",
      "34: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CBFFB518> to non-trainable\n",
      "35: Setting layer <keras.layers.merge.Add object at 0x00000154CC053940> to non-trainable\n",
      "36: Setting layer <keras.layers.core.Activation object at 0x00000154CC0CFEB8> to non-trainable\n",
      "37: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC0CFE10> to non-trainable\n",
      "38: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC13A588> to non-trainable\n",
      "39: Setting layer <keras.layers.core.Activation object at 0x00000154CC1729E8> to non-trainable\n",
      "40: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC1C0BE0> to non-trainable\n",
      "41: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC1B59B0> to non-trainable\n",
      "42: Setting layer <keras.layers.core.Activation object at 0x00000154CC208898> to non-trainable\n",
      "43: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC2A0550> to non-trainable\n",
      "44: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC2EB710> to non-trainable\n",
      "45: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC2912E8> to non-trainable\n",
      "46: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC365048> to non-trainable\n",
      "47: Setting layer <keras.layers.merge.Add object at 0x00000154CC3BDF98> to non-trainable\n",
      "48: Setting layer <keras.layers.core.Activation object at 0x00000154CC433BA8> to non-trainable\n",
      "49: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC4338D0> to non-trainable\n",
      "50: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC496080> to non-trainable\n",
      "51: Setting layer <keras.layers.core.Activation object at 0x00000154CC4EF5F8> to non-trainable\n",
      "52: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC5282E8> to non-trainable\n",
      "53: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC521E48> to non-trainable\n",
      "54: Setting layer <keras.layers.core.Activation object at 0x00000154CC585278> to non-trainable\n",
      "55: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC6089B0> to non-trainable\n",
      "56: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC5FC908> to non-trainable\n",
      "57: Setting layer <keras.layers.merge.Add object at 0x00000154CC6A0BA8> to non-trainable\n",
      "58: Setting layer <keras.layers.core.Activation object at 0x00000154CC72B240> to non-trainable\n",
      "59: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC72B0B8> to non-trainable\n",
      "60: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC772BA8> to non-trainable\n",
      "61: Setting layer <keras.layers.core.Activation object at 0x00000154CC7BBC50> to non-trainable\n",
      "62: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC80FE48> to non-trainable\n",
      "63: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CC855A20> to non-trainable\n",
      "64: Setting layer <keras.layers.core.Activation object at 0x00000154CC86D080> to non-trainable\n",
      "65: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154CC8F07B8> to non-trainable\n",
      "66: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154CB6DAD30> to non-trainable\n",
      "67: Setting layer <keras.layers.merge.Add object at 0x00000154CB7ECC88> to non-trainable\n",
      "68: Setting layer <keras.layers.core.Activation object at 0x00000154D1B72D68> to non-trainable\n",
      "69: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1B797B8> to non-trainable\n",
      "70: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1B6A550> to non-trainable\n",
      "71: Setting layer <keras.layers.core.Activation object at 0x00000154D1B462B0> to non-trainable\n",
      "72: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1B2CA20> to non-trainable\n",
      "73: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1B3A208> to non-trainable\n",
      "74: Setting layer <keras.layers.core.Activation object at 0x00000154D1B1D6D8> to non-trainable\n",
      "75: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1AF2D68> to non-trainable\n",
      "76: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1AF9208> to non-trainable\n",
      "77: Setting layer <keras.layers.merge.Add object at 0x00000154D1AD65F8> to non-trainable\n",
      "78: Setting layer <keras.layers.core.Activation object at 0x00000154D1ABA438> to non-trainable\n",
      "79: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1ABAAC8> to non-trainable\n",
      "80: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1A96B70> to non-trainable\n",
      "81: Setting layer <keras.layers.core.Activation object at 0x00000154D1A8F278> to non-trainable\n",
      "82: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1A6DD68> to non-trainable\n",
      "83: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1A73780> to non-trainable\n",
      "84: Setting layer <keras.layers.core.Activation object at 0x00000154D1A584E0> to non-trainable\n",
      "85: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1A2D978> to non-trainable\n",
      "86: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1A169E8> to non-trainable\n",
      "87: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1A39390> to non-trainable\n",
      "88: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D19F44E0> to non-trainable\n",
      "89: Setting layer <keras.layers.merge.Add object at 0x00000154D19D79E8> to non-trainable\n",
      "90: Setting layer <keras.layers.core.Activation object at 0x00000154D19B4978> to non-trainable\n",
      "91: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D19B4780> to non-trainable\n",
      "92: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1997710> to non-trainable\n",
      "93: Setting layer <keras.layers.core.Activation object at 0x00000154D19815C0> to non-trainable\n",
      "94: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1965128> to non-trainable\n",
      "95: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D196E0B8> to non-trainable\n",
      "96: Setting layer <keras.layers.core.Activation object at 0x00000154D1950358> to non-trainable\n",
      "97: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D19266D8> to non-trainable\n",
      "98: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D192DD68> to non-trainable\n",
      "99: Setting layer <keras.layers.merge.Add object at 0x00000154D1901278> to non-trainable\n",
      "100: Setting layer <keras.layers.core.Activation object at 0x00000154D18E58D0> to non-trainable\n",
      "101: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D18E5EF0> to non-trainable\n",
      "102: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D18D1A58> to non-trainable\n",
      "103: Setting layer <keras.layers.core.Activation object at 0x00000154D18B6F28> to non-trainable\n",
      "104: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D189DA20> to non-trainable\n",
      "105: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D18A7A90> to non-trainable\n",
      "106: Setting layer <keras.layers.core.Activation object at 0x00000154D188A128> to non-trainable\n",
      "107: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1868630> to non-trainable\n",
      "108: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D185F5C0> to non-trainable\n",
      "109: Setting layer <keras.layers.merge.Add object at 0x00000154D184AA90> to non-trainable\n",
      "110: Setting layer <keras.layers.core.Activation object at 0x00000154D181EC18> to non-trainable\n",
      "111: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D181EE10> to non-trainable\n",
      "112: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D180B630> to non-trainable\n",
      "113: Setting layer <keras.layers.core.Activation object at 0x00000154D17EF358> to non-trainable\n",
      "114: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D17DF400> to non-trainable\n",
      "115: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D17D8748> to non-trainable\n",
      "116: Setting layer <keras.layers.core.Activation object at 0x00000154D17BB2E8> to non-trainable\n",
      "117: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1798208> to non-trainable\n",
      "118: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D17A85C0> to non-trainable\n",
      "119: Setting layer <keras.layers.merge.Add object at 0x00000154D177CCC0> to non-trainable\n",
      "120: Setting layer <keras.layers.core.Activation object at 0x00000154D175F048> to non-trainable\n",
      "121: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D175F940> to non-trainable\n",
      "122: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1744518> to non-trainable\n",
      "123: Setting layer <keras.layers.core.Activation object at 0x00000154D1728D68> to non-trainable\n",
      "124: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1715BE0> to non-trainable\n",
      "125: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D171FDA0> to non-trainable\n",
      "126: Setting layer <keras.layers.core.Activation object at 0x00000154D17050F0> to non-trainable\n",
      "127: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D16D3A58> to non-trainable\n",
      "128: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D16BE908> to non-trainable\n",
      "129: Setting layer <keras.layers.merge.Add object at 0x00000154D16B7F28> to non-trainable\n",
      "130: Setting layer <keras.layers.core.Activation object at 0x00000154D169A748> to non-trainable\n",
      "131: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D169A1D0> to non-trainable\n",
      "132: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D167D780> to non-trainable\n",
      "133: Setting layer <keras.layers.core.Activation object at 0x00000154D1669CF8> to non-trainable\n",
      "134: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D164D5F8> to non-trainable\n",
      "135: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1654C88> to non-trainable\n",
      "136: Setting layer <keras.layers.core.Activation object at 0x00000154D1637780> to non-trainable\n",
      "137: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D160B1D0> to non-trainable\n",
      "138: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1615DA0> to non-trainable\n",
      "139: Setting layer <keras.layers.merge.Add object at 0x00000154D15EF588> to non-trainable\n",
      "140: Setting layer <keras.layers.core.Activation object at 0x00000154D15D5470> to non-trainable\n",
      "141: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D15D5908> to non-trainable\n",
      "142: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D15BD6A0> to non-trainable\n",
      "143: Setting layer <keras.layers.core.Activation object at 0x00000154D15A2A20> to non-trainable\n",
      "144: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1587160> to non-trainable\n",
      "145: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D158D828> to non-trainable\n",
      "146: Setting layer <keras.layers.core.Activation object at 0x00000154D1572048> to non-trainable\n",
      "147: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D15475C0> to non-trainable\n",
      "148: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1524668> to non-trainable\n",
      "149: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D154DCF8> to non-trainable\n",
      "150: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D150E358> to non-trainable\n",
      "151: Setting layer <keras.layers.merge.Add object at 0x00000154D14EA978> to non-trainable\n",
      "152: Setting layer <keras.layers.core.Activation object at 0x00000154D14CDA58> to non-trainable\n",
      "153: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D14CD6D8> to non-trainable\n",
      "154: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D14B3668> to non-trainable\n",
      "155: Setting layer <keras.layers.core.Activation object at 0x00000154D14A3630> to non-trainable\n",
      "156: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D1487208> to non-trainable\n",
      "157: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D147F908> to non-trainable\n",
      "158: Setting layer <keras.layers.core.Activation object at 0x00000154D146ACF8> to non-trainable\n",
      "159: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D143AF98> to non-trainable\n",
      "160: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D14476D8> to non-trainable\n",
      "161: Setting layer <keras.layers.merge.Add object at 0x00000154D1424828> to non-trainable\n",
      "162: Setting layer <keras.layers.core.Activation object at 0x00000154D13F86D8> to non-trainable\n",
      "163: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D13F8208> to non-trainable\n",
      "164: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D13EBBA8> to non-trainable\n",
      "165: Setting layer <keras.layers.core.Activation object at 0x00000154D13D02E8> to non-trainable\n",
      "166: Setting layer <keras.layers.convolutional.Conv2D object at 0x00000154D13B95F8> to non-trainable\n",
      "167: Setting layer <keras.layers.normalization.BatchNormalization object at 0x00000154D13C7438> to non-trainable\n",
      "168: Setting layer <keras.layers.core.Activation object at 0x00000154D139D9E8> to non-trainable\n",
      "169: Keeping layer <keras.layers.convolutional.Conv2D object at 0x00000154D1373C88> trainable\n",
      "170: Keeping layer <keras.layers.normalization.BatchNormalization object at 0x00000154D1382588> trainable\n",
      "171: Keeping layer <keras.layers.merge.Add object at 0x00000154D1356A58> trainable\n",
      "172: Keeping layer <keras.layers.core.Activation object at 0x00000154D1342DD8> trainable\n",
      "173: Keeping layer <keras.layers.pooling.AveragePooling2D object at 0x00000154D1342B70> trainable\n",
      "174: Setting layer <keras.models.Sequential object at 0x00000154D12F92E8> to non-trainable\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning attempt\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "\n",
    "# load pretrained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', \n",
    "                           include_top=False, \n",
    "                           input_shape=(224, 224, 3))\n",
    "\n",
    "# Load prediction layer\n",
    "model_clf = keras.models.load_model('ResNetTop_ValAcc7941.h5')\n",
    "\n",
    "# Connect\n",
    "last_flayer = resnet_model.output\n",
    "out = model_clf(last_flayer)\n",
    "\n",
    "# Collect\n",
    "resnet_ft = Model(resnet_model.input, out)\n",
    "\n",
    "# Fine-tune last layers\n",
    "for i in range(0, len(resnet_ft.layers)):\n",
    "    if i < 169 or i == 174:\n",
    "        print(\"%i: Setting layer %s to non-trainable\" % (i, str(resnet_ft.layers[i])))\n",
    "        resnet_ft.layers[i].trainable=False\n",
    "    else:\n",
    "        print(\"%i: Keeping layer %s trainable\" % (i, str(resnet_ft.layers[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192171 images belonging to 128 classes.\n",
      "Found 6309 images belonging to 128 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data generator\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Train\n",
    "target_size = (224,224)\n",
    "validation_dir = './valid'\n",
    "train_dir = './train'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        #rescale=1./255.\n",
    "        #rotation_range=10,\n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1,\n",
    "        #horizontal_flip=True,\n",
    "        preprocessing_function=preprocess_input\n",
    "      )\n",
    " \n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    " \n",
    "train_batchsize = 128\n",
    "val_batchsize = 128\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  6/200 [..............................] - ETA: 24:18 - loss: 13.2937 - acc: 0.0117"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-12debffcf0d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ResnetFineTune.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Illustrate issue with model starting at 0 accuracy\n",
    "optim = keras.optimizers.Adam(lr=(1e-5))\n",
    "\n",
    "# Compile the model\n",
    "resnet_ft.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optim,\n",
    "            metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = resnet_ft.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=200,\n",
    "        epochs=300,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint('ResnetFineTune.h5', monitor='val_loss', verbose=2, save_best_only=True, mode='auto', period=1)]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
