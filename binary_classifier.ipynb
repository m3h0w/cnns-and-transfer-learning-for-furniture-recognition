{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'binary_classifier.ipynb', 'Classification.ipynb', 'data', 'feature_extractor.py', 'feature_extractor_linux.py', 'keras_test.py', 'LICENSE', 'mlp_200_100.pkl', 'README.md', 'rescale.py', 'Silllina.ipynb', 'submission.csv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from sklearn import linear_model\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "FEATURES_LOCATION = './data/features/'\n",
    "F_CORE = 'cnn_features_'\n",
    "\n",
    "\n",
    "def get_label_from_path(file):\n",
    "    return file.split('\\\\')[1].split('.')[0]\n",
    "\n",
    "def load_data(mode):\n",
    "    if(mode == 'test'):\n",
    "        pickle_path = F_CORE + mode\n",
    "        data = pickle.load(open(FEATURES_LOCATION + pickle_path + '.pkl', 'rb'))\n",
    "        to_return = {}\n",
    "        for key, value in list(data.items()):\n",
    "            to_return[get_label_from_path(key)] = value.reshape(1,-1)\n",
    "        return to_return, None\n",
    "    \n",
    "    pickle_path = F_CORE + mode + '_'\n",
    "    \n",
    "    data = {}\n",
    "    for i in range(1,129):\n",
    "        data[i] = pickle.load(open(FEATURES_LOCATION + pickle_path + str(i) + '.pkl', 'rb'))\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    for key, value in list(data.items()):\n",
    "        #change all labels that is not the chosen label to 0, and change the chosen label to 1\n",
    "        the_class = key\n",
    "        features = np.array(list(value.values()))\n",
    "        for feature in features:\n",
    "            y.append(the_class)\n",
    "            X.append(feature)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape:  (192171, 2048)\n",
      "ytrain.shape:  (192171,)\n",
      "X_val.shape:  (6309, 2048)\n",
      "y_val.shape:  (6309,)\n"
     ]
    }
   ],
   "source": [
    "#TODO: use perceptron instead of logreg, use subset of data\n",
    "\n",
    "X_train, y_train = load_data('train')\n",
    "print(\"Xtrain.shape: \",X_train.shape)\n",
    "print(\"ytrain.shape: \",y_train.shape)\n",
    "# load the training data and rewrite the classes\n",
    "X_val, y_val = load_data('valid')\n",
    "print(\"X_val.shape: \",X_val.shape)\n",
    "print(\"y_val.shape: \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  1\n",
      "accuracy:  0.9950863845300365\n",
      "class:  2\n",
      "accuracy:  0.9939768584561737\n",
      "class:  3\n",
      "accuracy:  0.9919163100332857\n",
      "class:  4\n",
      "accuracy:  0.9938183547313362\n",
      "class:  5\n",
      "accuracy:  0.9968299255032493\n",
      "class:  6\n",
      "accuracy:  0.9968299255032493\n",
      "class:  7\n",
      "accuracy:  0.9969884292280868\n",
      "class:  8\n",
      "accuracy:  0.9941353621810113\n",
      "class:  9\n",
      "accuracy:  0.9939768584561737\n",
      "class:  10\n",
      "accuracy:  0.9963544143287367\n",
      "class:  11\n",
      "accuracy:  0.9957203994293866\n",
      "class:  12\n",
      "accuracy:  0.9954033919797115\n",
      "class:  13\n",
      "accuracy:  0.9933428435568236\n",
      "class:  14\n",
      "accuracy:  0.9914407988587732\n",
      "class:  15\n",
      "accuracy:  0.992550324932636\n",
      "class:  16\n",
      "accuracy:  0.9977809478522746\n",
      "class:  17\n",
      "accuracy:  0.9946108733555239\n",
      "class:  18\n",
      "accuracy:  0.9936598510064987\n",
      "class:  19\n",
      "accuracy:  0.9909652876842606\n",
      "class:  20\n",
      "accuracy:  0.9971469329529244\n",
      "class:  21\n",
      "accuracy:  0.9949278808051989\n",
      "class:  22\n",
      "accuracy:  0.9936598510064987\n",
      "class:  23\n",
      "accuracy:  0.9935013472816612\n",
      "class:  24\n",
      "accuracy:  0.995244888254874\n",
      "class:  25\n",
      "accuracy:  0.9939768584561737\n",
      "class:  26\n",
      "accuracy:  0.995244888254874\n",
      "class:  27\n",
      "accuracy:  0.9919163100332857\n",
      "class:  28\n",
      "accuracy:  0.9947693770803614\n",
      "class:  29\n",
      "accuracy:  0.9947693770803614\n",
      "class:  30\n",
      "accuracy:  0.9960374068790616\n",
      "class:  31\n",
      "accuracy:  0.9914407988587732\n",
      "class:  32\n",
      "accuracy:  0.9950863845300365\n",
      "class:  33\n",
      "accuracy:  0.9961959106038992\n",
      "class:  34\n",
      "accuracy:  0.995561895704549\n",
      "class:  35\n",
      "accuracy:  0.9903312727849104\n",
      "class:  36\n",
      "accuracy:  0.9621176097638294\n",
      "class:  37\n",
      "accuracy:  0.9933428435568236\n",
      "class:  38\n",
      "accuracy:  0.9960374068790616\n",
      "class:  39\n",
      "accuracy:  0.9917578063084482\n",
      "class:  40\n",
      "accuracy:  0.9946108733555239\n",
      "class:  41\n",
      "accuracy:  0.9980979553019496\n",
      "class:  42\n",
      "accuracy:  0.9901727690600729\n",
      "class:  43\n",
      "accuracy:  0.9977809478522746\n",
      "class:  44\n",
      "accuracy:  0.9985734664764622\n",
      "class:  45\n",
      "accuracy:  0.9942938659058488\n",
      "class:  46\n",
      "accuracy:  0.9965129180535742\n",
      "class:  47\n",
      "accuracy:  0.9963544143287367\n",
      "class:  48\n",
      "accuracy:  0.9968299255032493\n",
      "class:  49\n",
      "accuracy:  0.9936598510064987\n",
      "class:  50\n",
      "accuracy:  0.9917578063084482\n",
      "class:  51\n",
      "accuracy:  0.990489776509748\n",
      "class:  52\n",
      "accuracy:  0.9938183547313362\n",
      "class:  53\n",
      "accuracy:  0.9954033919797115\n",
      "class:  54\n",
      "accuracy:  0.9941353621810113\n",
      "class:  55\n",
      "accuracy:  0.997622444127437\n",
      "class:  56\n",
      "accuracy:  0.9992074813758123\n",
      "class:  57\n",
      "accuracy:  0.9954033919797115\n",
      "class:  58\n",
      "accuracy:  0.997305436677762\n",
      "class:  59\n",
      "accuracy:  0.9941353621810113\n",
      "class:  60\n",
      "accuracy:  0.992867332382311\n",
      "class:  61\n",
      "accuracy:  0.9863686796639721\n",
      "class:  62\n",
      "accuracy:  0.997622444127437\n",
      "class:  63\n",
      "accuracy:  0.9911237914090981\n",
      "class:  64\n",
      "accuracy:  0.9977809478522746\n",
      "class:  65\n",
      "accuracy:  0.995244888254874\n",
      "class:  66\n",
      "accuracy:  0.9931843398319861\n",
      "class:  67\n",
      "accuracy:  0.9950863845300365\n",
      "class:  68\n",
      "accuracy:  0.9985734664764622\n",
      "class:  69\n",
      "accuracy:  0.9957203994293866\n",
      "class:  70\n",
      "accuracy:  0.9787605008717705\n",
      "class:  71\n",
      "accuracy:  0.9922333174829608\n",
      "class:  72\n",
      "accuracy:  0.9960374068790616\n",
      "class:  73\n",
      "accuracy:  0.9984149627516247\n",
      "class:  74\n",
      "accuracy:  0.9949278808051989\n",
      "class:  75\n",
      "accuracy:  0.9882707243620225\n",
      "class:  76\n",
      "accuracy:  0.9969884292280868\n",
      "class:  77\n",
      "accuracy:  0.995561895704549\n",
      "class:  78\n",
      "accuracy:  0.9979394515771121\n",
      "class:  79\n",
      "accuracy:  0.9909652876842606\n",
      "class:  80\n",
      "accuracy:  0.9954033919797115\n",
      "class:  81\n",
      "accuracy:  0.9977809478522746\n",
      "class:  82\n",
      "accuracy:  0.9914407988587732\n",
      "class:  83\n",
      "accuracy:  0.995244888254874\n",
      "class:  84\n",
      "accuracy:  0.9946108733555239\n",
      "class:  85\n",
      "accuracy:  0.9971469329529244\n",
      "class:  86\n",
      "accuracy:  0.9927088286574735\n",
      "class:  87\n",
      "accuracy:  0.9919163100332857\n",
      "class:  88\n",
      "accuracy:  0.9946108733555239\n",
      "class:  89\n",
      "accuracy:  0.9961959106038992\n",
      "class:  90\n",
      "accuracy:  0.995244888254874\n",
      "class:  91\n",
      "accuracy:  0.9874782057378348\n",
      "class:  92\n",
      "accuracy:  0.9968299255032493\n",
      "class:  93\n",
      "accuracy:  0.995244888254874\n",
      "class:  94\n",
      "accuracy:  0.9903312727849104\n",
      "class:  95\n",
      "accuracy:  0.9968299255032493\n",
      "class:  96\n",
      "accuracy:  0.995561895704549\n",
      "class:  97\n",
      "accuracy:  0.9941353621810113\n",
      "class:  98\n",
      "accuracy:  0.9938183547313362\n",
      "class:  99\n",
      "accuracy:  0.9939768584561737\n",
      "class:  100\n",
      "accuracy:  0.9946108733555239\n",
      "class:  101\n",
      "accuracy:  0.9966714217784118\n",
      "class:  102\n",
      "accuracy:  0.9968299255032493\n",
      "class:  103\n",
      "accuracy:  0.992550324932636\n",
      "class:  104\n",
      "accuracy:  0.9879537169123475\n",
      "class:  105\n",
      "accuracy:  0.9922333174829608\n",
      "class:  106\n",
      "accuracy:  0.9968299255032493\n",
      "class:  107\n",
      "accuracy:  0.9968299255032493\n",
      "class:  108\n",
      "accuracy:  0.9906482802345855\n",
      "class:  109\n",
      "accuracy:  0.9966714217784118\n",
      "class:  110\n",
      "accuracy:  0.9941353621810113\n",
      "class:  111\n",
      "accuracy:  0.9968299255032493\n",
      "class:  112\n",
      "accuracy:  0.9922333174829608\n",
      "class:  113\n",
      "accuracy:  0.9947693770803614\n",
      "class:  114\n",
      "accuracy:  0.995244888254874\n",
      "class:  115\n",
      "accuracy:  0.9935013472816612\n",
      "class:  116\n",
      "accuracy:  0.995244888254874\n",
      "class:  117\n",
      "accuracy:  0.9947693770803614\n",
      "class:  118\n",
      "accuracy:  0.9938183547313362\n",
      "class:  119\n",
      "accuracy:  0.9985734664764622\n",
      "class:  120\n",
      "accuracy:  0.9927088286574735\n",
      "class:  121\n",
      "accuracy:  0.995561895704549\n",
      "class:  122\n",
      "accuracy:  0.9968299255032493\n",
      "class:  123\n",
      "accuracy:  0.9984149627516247\n",
      "class:  124\n",
      "accuracy:  0.9958789031542241\n",
      "class:  125\n",
      "accuracy:  0.9961959106038992\n",
      "class:  126\n",
      "accuracy:  0.9942938659058488\n",
      "class:  127\n",
      "accuracy:  0.9939768584561737\n",
      "class:  128\n",
      "accuracy:  0.9915993025836107\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES_TO_TEST = 129 # number of classes to do binary classification on, 129 = max\n",
    "score_list = []\n",
    "for i in range(1,NUM_CLASSES_TO_TEST):\n",
    "    class_i_X_train = np.copy(X_train)\n",
    "    class_i_y_train = np.copy(y_train)\n",
    "    class_i_X_val = np.copy(X_val)\n",
    "    class_i_y_val = np.copy(y_val)\n",
    "    \n",
    "    # change the trianing data\n",
    "    for j in range(0,len(class_i_y_train)):\n",
    "        if class_i_y_train[j] != i:\n",
    "            class_i_y_train[j] = 0\n",
    "        else:\n",
    "            class_i_y_train[j] = 1\n",
    "        \n",
    "    # change the validation data\n",
    "    for k in range(0,len(class_i_y_val)):\n",
    "        if class_i_y_val[k] != i:\n",
    "            \n",
    "            class_i_y_val[k] = 0\n",
    "        else:\n",
    "            class_i_y_val[k] = 1\n",
    "            \n",
    "    '''  \n",
    "    logreg = linear_model.LogisticRegression()\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    logreg.fit(class_i_X_train, class_i_y_train)\n",
    "    print(\"training complete\")\n",
    "    score = logreg.score(class_i_X_val,class_i_y_val)\n",
    "    score_list.append(score)\n",
    "    print(\"accuracy: \",score)\n",
    "    '''\n",
    "    \n",
    "    ptron = linear_model.Perceptron()\n",
    "    ptron.fit(class_i_X_train,class_i_y_train)\n",
    "    score = ptron.score(class_i_X_val,class_i_y_val)\n",
    "    score_list.append(score)\n",
    "    print(\"class: \",i)\n",
    "    print(\"accuracy: \",score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
