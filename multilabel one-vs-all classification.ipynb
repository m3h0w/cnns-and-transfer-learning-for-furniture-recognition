{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'binary_classifier.ipynb', 'Classification.ipynb', 'data', 'feature_extractor.py', 'feature_extractor_linux.py', 'keras_test.py', 'LICENSE', 'mlp_200_100.pkl', 'multilabel one-vs-all classification.ipynb', 'README.md', 'rescale.py', 'Silllina.ipynb', 'submission.csv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "FEATURES_LOCATION = './data/features/'\n",
    "F_CORE = 'cnn_features_'\n",
    "\n",
    "\n",
    "def get_label_from_path(file):\n",
    "    return file.split('\\\\')[1].split('.')[0]\n",
    "\n",
    "def load_data(mode):\n",
    "    if(mode == 'test'):\n",
    "        pickle_path = F_CORE + mode\n",
    "        data = pickle.load(open(FEATURES_LOCATION + pickle_path + '.pkl', 'rb'))\n",
    "        to_return = {}\n",
    "        for key, value in list(data.items()):\n",
    "            to_return[get_label_from_path(key)] = value.reshape(1,-1)\n",
    "        return to_return, None\n",
    "    \n",
    "    pickle_path = F_CORE + mode + '_'\n",
    "    \n",
    "    data = {}\n",
    "    for i in range(1,129):\n",
    "        data[i] = pickle.load(open(FEATURES_LOCATION + pickle_path + str(i) + '.pkl', 'rb'))\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    for key, value in list(data.items()):\n",
    "        #change all labels that is not the chosen label to 0, and change the chosen label to 1\n",
    "        the_class = key\n",
    "        features = np.array(list(value.values()))\n",
    "        for feature in features:\n",
    "            y.append(the_class)\n",
    "            X.append(feature)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape:  (192171, 2048)\n",
      "ytrain.shape:  (192171,)\n",
      "X_val.shape:  (6309, 2048)\n",
      "y_val.shape:  (6309,)\n"
     ]
    }
   ],
   "source": [
    "#TODO: use perceptron instead of logreg, use subset of data\n",
    "\n",
    "X_train, y_train = load_data('train')\n",
    "print(\"Xtrain.shape: \",X_train.shape)\n",
    "print(\"ytrain.shape: \",y_train.shape)\n",
    "# load the training data and rewrite the classes\n",
    "X_val, y_val = load_data('valid')\n",
    "print(\"X_val.shape: \",X_val.shape)\n",
    "print(\"y_val.shape: \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score matrix completed\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES_TO_TEST = 129 # number of classes to do binary classification on, 129 = max\n",
    "score_mat = np.zeros([X_val.shape[0],129])\n",
    "\n",
    "for i in range(1,NUM_CLASSES_TO_TEST):\n",
    "    class_i_X_train = np.copy(X_train)\n",
    "    class_i_y_train = np.copy(y_train)\n",
    "    class_i_X_val = np.copy(X_val)\n",
    "    class_i_y_val = np.copy(y_val)\n",
    "    \n",
    "    # change the trianing data\n",
    "    for j in range(0,len(class_i_y_train)):\n",
    "        if class_i_y_train[j] != i:\n",
    "            class_i_y_train[j] = 0\n",
    "        else:\n",
    "            class_i_y_train[j] = 1\n",
    "        \n",
    "    # change the validation data\n",
    "    for k in range(0,len(class_i_y_val)):\n",
    "        if class_i_y_val[k] != i:\n",
    "            \n",
    "            class_i_y_val[k] = 0\n",
    "        else:\n",
    "            class_i_y_val[k] = 1\n",
    "            \n",
    "    '''  \n",
    "    logreg = linear_model.LogisticRegression()\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    logreg.fit(class_i_X_train, class_i_y_train)\n",
    "    print(\"training complete\")\n",
    "    score = logreg.score(class_i_X_val,class_i_y_val)\n",
    "    score_list.append(score)\n",
    "    print(\"accuracy: \",score)\n",
    "    '''\n",
    "    # save result in score_mat[feature_num, i]\n",
    "    \n",
    "    ptron = linear_model.Perceptron()\n",
    "    ptron.fit(class_i_X_train,class_i_y_train)\n",
    "    preds = ptron.predict(class_i_X_val)\n",
    "    \n",
    "    for p in range(0,len(preds)):\n",
    "      score_mat[p,i] = preds[p]\n",
    "\n",
    "print(\"score matrix completed\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6309,)\n",
      "6309\n",
      "accuracy:  0.5534950071326676\n"
     ]
    }
   ],
   "source": [
    "#I now have a matrix of shape: \"X_val.shape[0],129\" containing the votes\n",
    "# now make every class \"vote\" for the label they think it was. \n",
    "# 1 = class thinks it was itself, 0 = class thinks it was another class.\n",
    "#vote_list = np.empty([score_mat.shape[0],1])\n",
    "vote_list = np.zeros([score_mat.shape[0]])\n",
    "for i in range(0,score_mat.shape[0]):\n",
    "    for j in range(0,score_mat.shape[1]):\n",
    "        # if a class think its the class, then save it in the list\n",
    "        # this is flawed since it first come first serve.\n",
    "        if score_mat[i,j] == 1:\n",
    "            # feature i, is now predicted to be feature j\n",
    "            vote_list[i] = j\n",
    "            break\n",
    "        \n",
    "# now calculate accuracy\n",
    "print(y_val.shape)\n",
    "print(len(vote_list))\n",
    "accuracy = accuracy_score(vote_list,y_val)\n",
    "print(\"accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
